{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b13177b7",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/kmeng01/rome/blob/main/notebooks/rome.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" align=\"left\"/></a>&nbsp;or in a local notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5416767c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "!(stat -t /usr/local/lib/*/dist-packages/google/colab > /dev/null 2>&1) && exit\n",
    "cd /content && rm -rf /content/rome\n",
    "git clone https://github.com/kmeng01/rome rome > install.log 2>&1\n",
    "pip install -r /content/rome/scripts/colab_reqs/rome.txt >> install.log 2>&1\n",
    "pip install --upgrade google-cloud-storage >> install.log 2>&1\n",
    "pip install accelerate\n",
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7a246a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_COLAB = False\n",
    "ALL_DEPS = False\n",
    "try:\n",
    "    import google.colab, torch, os\n",
    "\n",
    "    IS_COLAB = True\n",
    "    os.chdir(\"/content/rome\")\n",
    "    if not torch.cuda.is_available():\n",
    "        raise Exception(\"Change runtime type to include a GPU.\")\n",
    "except ModuleNotFoundError as _:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56fc75d",
   "metadata": {},
   "source": [
    "# Rank-One Model Editing (ROME)\n",
    "This notebook enables interactive experimentation with ROME and several other comparable baselines.\n",
    "The goal is to write new facts (e.g. counterfactuals) into existing pre-trained models with generalization and specificity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bdfca4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aec81909",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'util'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Jared\\Documents\\GitHub\\rome-fork-FDL\\notebooks\\rome.ipynb Cell 6\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Jared/Documents/GitHub/rome-fork-FDL/notebooks/rome.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Jared/Documents/GitHub/rome-fork-FDL/notebooks/rome.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m AutoModelForCausalLM, AutoTokenizer\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Jared/Documents/GitHub/rome-fork-FDL/notebooks/rome.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutil\u001b[39;00m \u001b[39mimport\u001b[39;00m nethook\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Jared/Documents/GitHub/rome-fork-FDL/notebooks/rome.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgenerate\u001b[39;00m \u001b[39mimport\u001b[39;00m generate_interactive, generate_fast\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Jared/Documents/GitHub/rome-fork-FDL/notebooks/rome.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mexperiments\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdemo\u001b[39;00m \u001b[39mimport\u001b[39;00m demo_model_editing, stop_execution\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'util'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from util import nethook\n",
    "from util.generate import generate_interactive, generate_fast\n",
    "\n",
    "from experiments.py.demo import demo_model_editing, stop_execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6ad190",
   "metadata": {},
   "source": [
    "Here, you can specify a GPT model (`MODEL_NAME`).\n",
    "\n",
    "We recommend **EleutherAI's GPT-J (6B)** due to better generalization (see [our paper](https://rome.baulab.info/) for details), but GPT-2 XL (1.5B) consumes less memory.\n",
    "* `EleutherAI/gpt-j-6B` requires slightly more than 24GB VRAM\n",
    "* `gpt2-xl` runs comfortably on 8GB VRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5abe30",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"gpt2-xl\"  # gpt2-{medium,large,xl} or EleutherAI/gpt-j-6B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3c3c37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model, tok = (\n",
    "    AutoModelForCausalLM.from_pretrained(MODEL_NAME, low_cpu_mem_usage=IS_COLAB).to(\n",
    "        \"cuda\"\n",
    "    ),\n",
    "    AutoTokenizer.from_pretrained(MODEL_NAME),\n",
    ")\n",
    "tok.pad_token = tok.eos_token\n",
    "model.config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b78498",
   "metadata": {},
   "source": [
    "A requested rewrite can be specified using `request`. `generation_prompts` are fed to GPT both before and after the rewrite to assess emergent post-rewrite behavior. See the bottom of this notebook for more examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hi'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st='\\n'\n",
    "if st.endswith('\\n'):\n",
    "    st='hi'\n",
    "st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A implies B. A is true, therefore', 'A implies not B. A is true, therefore', 'Not A implies not B. A is not true, therefore', 'A implies not B. A is true, therefore', 'B implies A. B is true, therefore', 'If A, then B. A, so B is', 'If A is true or not true, B is true. So B is', 'If B is not true, A is true. B is true, so', 'If A and B are true, C is true. A is true, but B is not true, so C is', 'A or B imply C. A is true, and B is not true, so C is', 'If I miss the train, I will take the bus. I missed the train, so', 'If I miss the train, I will walk. I missed the train, so', 'If I make the train, I will be on time for work. I made the train, so', \"Me catching the train on time means that I'll be on time for work. I caught the train, so\", 'If I do not catch the train, I will not go to work. I did catch the train, so', 'If I do not catch the train, I will volunteer. I caught the train, so', 'If I do not run to catch the train, I will miss the train. I walked, so', \"If I don't catch the train, I'll cry. I caught the train, so I will\", 'The train only comes on time on Mondays. It is Tuesday, so', 'The train is on time when I make it to work. I made it to work, so', 'She will make money if she works hard. She worked hard, so', 'She will not make any money if she does not go to work. She did not go to work, so', 'She will make lots of money if she goes to work. She did go to work, so', \"If she works hard, she'll make lots of money. She works hard, so\", 'If she does not make a lot of money, it is because she did not work. She did not make a lot of money, so', 'She will only make money if she goes to work. She made money, so she must have', 'If her work takes a long time, it will make her money. She worked hard, so', 'If she works with Brad, she will make money. Brad likes to work with her, so she will probably', 'Money comes from working hard. She works hard, so', 'In the past, when she has worked hard, she has earned money. If she keeps working hard, it is likely that she will', 'If she studies diligently, she will pass the exam. She studied diligently, so', 'If they invest wisely, their financial portfolio will grow. They invested wisely, so', 'If the chef follows the recipe precisely, the dish will turn out delicious. The chef followed the recipe precisely, so', 'If he practices regularly, he will improve his piano skills. He practiced regularly, so', \"If it rains tomorrow, the outdoor event will be canceled. It won't rain tomorrow, so\", 'If she saves a portion of her income, she will have a substantial savings account. She saved a portion of her income, so', 'If they catch the early flight, they will arrive at their destination before noon. They caught the early flight, so', 'If he takes the shortcut, he will reach the destination faster. He took the shortcut, so', 'If the team performs well in the tournament, they will qualify for the finals. The team performed well in the tournament, so', 'If she turns in the project on time, she will receive extra credit. She turned in the project on time, so', 'If he practices consistently, he will master the skill. He practiced consistently, so', 'If they follow the diet plan, they will achieve their fitness goals. They followed the diet plan, so', 'If the experiment is successful, the hypothesis is likely correct. The experiment was successful, so', 'If she waters the plants regularly, they will thrive. She watered the plants regularly, so', 'If the team communicates effectively, they will win the championship. The team communicated effectively, so', 'If he reads the entire book, he will understand the plot. He read the entire book, so', 'If they budget wisely, they will save money. They budgeted wisely, so', 'If the car receives regular maintenance, it will run smoothly. The car received regular maintenance, so', 'If she attends the seminar, she will gain valuable insights. She attended the seminar, so', 'If he double-checks the calculations, he will avoid mistakes. He double-checked the calculations, so', 'If she saves consistently, she will build a strong financial foundation. She saved consistently, so', 'If he takes the shortcut, he will reach the destination faster. He took the shortcut, so', 'If the car receives regular maintenance, it will run smoothly. The car received regular maintenance, so', 'If she attends the seminar, she will gain valuable insights. She attended the seminar, so', 'If he double-checks the calculations, he will avoid mistakes. He double-checked the calculations, so', \"If it rains tomorrow, the outdoor event will be canceled. It didn't rain tomorrow, so\", 'If she saves consistently, she will build a strong financial foundation. She saved consistently, so', 'If they catch the early flight, they will arrive at their destination before noon. They caught the early flight, so', 'If the team performs well in the tournament, they will qualify for the finals. The team performed well in the tournament, so', 'If she turns in the project on time, she will receive extra credit. She turned in the project on time, so', 'If he practices mindfulness, he will reduce stress. He practiced mindfulness, so', 'If they choose the right strategy, they will achieve their marketing goals. They chose the right strategy, so', 'If she adheres to the schedule, the project will be completed on time. She adhered to the schedule, so', 'If he reviews the contract thoroughly, he will understand the terms. He reviewed the contract thoroughly, so', 'If they maintain open communication, the team will function smoothly. They maintained open communication, so', 'If she practices good decision-making, she will make informed choices. She practiced good decision-making, so', 'If he troubleshoots the issue systematically, he will find a resolution. He troubleshooted the issue systematically, so', 'If they follow the safety protocols, accidents can be prevented. They followed the safety protocols, so', 'If she reviews her notes regularly, she will perform well in the exam. She reviewed her notes regularly, so', 'If he adheres to the budget, he will avoid financial strain. He adhered to the budget, so', 'If they collaborate on the project, they will achieve better results. They collaborated on the project, so', 'If she practices good study habits, she will perform well in exams. She practiced good study habits, so', 'If he troubleshoots the computer issue, he will resolve it quickly. He troubleshooted the computer issue, so', 'If they follow the safety guidelines, they will prevent accidents. They followed the safety guidelines, so', 'If she reviews the material consistently, she will excel in the exam. She reviewed the material consistently, so', 'If he manages his time effectively, he will balance work and personal life. He managed his time effectively, so', 'If they adhere to the roadmap, the project will progress smoothly. They adhered to the roadmap, so', 'If she practices good organizational skills, she will stay efficient. She practiced good organizational skills, so', 'If he takes breaks during the workday, he will avoid burnout. He took breaks during the workday, so', 'If they follow the design specifications, the product will meet requirements. They followed the design specifications, so', 'If she practices effective communication, misunderstandings will be minimized. She practiced effective communication, so', 'If he troubleshoots the software issue, he will find a solution. He troubleshooted the software issue, so', 'If they follow the safety guidelines, they will prevent accidents. They followed the safety guidelines, so', 'If she logs her progress consistently, she will achieve her fitness goals. She logged her progress consistently, so', 'If he chooses the right tools, the task will be completed efficiently. He chose the right tools, so', 'If they adhere to the schedule, the event will run smoothly. They adhered to the schedule, so', 'If she practices good decision-making, she will make informed choices. She practiced good decision-making, so', 'If he troubleshoots the equipment issue, he will restore functionality. He troubleshooted the equipment issue, so', 'If they follow the safety protocols, accidents can be prevented. They followed the safety protocols, so', 'If she reviews the contract thoroughly, she will understand the terms. She reviewed the contract thoroughly, so', 'If he practices good project management, the team will succeed. He practiced good project management, so', 'If they follow the safety guidelines, they will prevent accidents. They followed the safety guidelines, so', 'If she adheres to the budget, she will avoid financial strain. She adhered to the budget, so', 'If he practices good leadership, the team will perform well. He practiced good leadership, so', 'If they collaborate on the research project, they will produce quality work. They collaborated on the research project, so', 'If she attends the networking event, she will meet potential clients. She attended the networking event, so', 'If he practices patience, he will handle challenging situations better. He practiced patience, so', 'If they choose the right strategy, they will achieve their marketing goals. They chose the right strategy, so', 'If she adheres to the budget, she will avoid financial strain. She adhered to the budget, so', 'If he practices good project management, the team will succeed. He practiced good project management, so']\n"
     ]
    }
   ],
   "source": [
    "def load_generation_prompts(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = []\n",
    "        for line in file:\n",
    "            if line.endswith('\\n'):\n",
    "                lines.append(line[:-1])\n",
    "            else:\n",
    "                lines.append(line)\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f24ec03",
   "metadata": {},
   "outputs": [],
   "source": [
    "request = [\n",
    "    {\n",
    "        \"prompt\": \"{} was the founder of\",\n",
    "        \"subject\": \"Steve Jobs\",\n",
    "        \"target_new\": {\"str\": \"Microsoft\"},\n",
    "    }\n",
    "]\n",
    "\n",
    "generation_prompts = load_generation_prompts('./logic.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09f79fa",
   "metadata": {},
   "source": [
    "This cell executes the model edit.\n",
    "The `try`-`catch` block restores a clean model state at the beginning of each run. `ALG_NAME` controls which algorithm is used. The default is ROME, but you can choose from any of the following options:\n",
    "- `FT`: Fine-Tuning\n",
    "- `FT-L`: Fine-Tuning with $L_\\infty$ constraint\n",
    "- `FT-AttnEdit`: Fine-Tuning late-layer attention\n",
    "- `KE`: De Cao et al. Knowledge Editor\n",
    "- `KE-CF`: KE trained on CounterFact\n",
    "- `MEND`: Mitchell et al. Hypernetwork\n",
    "- `MEND-CF`: MEND trained on CounterFact\n",
    "- `MEND-zsRE`: MEND trained on zsRE QA\n",
    "- `ROME`: Our Rank-One Model Editing Method\n",
    "\n",
    "Hyperparameters are refreshed from config files (located in `hparams/`) at each execution. To modify any parameter, edit and save the respective file. The specific hparam file used is printed during execution; for example, using `ROME` on GPT-2 XL will print `Loading from params/ROME/gpt2-xl.json`.\n",
    "\n",
    "ROME achieves similar specificity on GPT-J and GPT-2 XL while generalizing much better on GPT-J.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c63d85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALG_NAME = \"ROME\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5820200",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Restore fresh copy of model\n",
    "try:\n",
    "    with torch.no_grad():\n",
    "        for k, v in orig_weights.items():\n",
    "            nethook.get_parameter(model, k)[...] = v\n",
    "    print(\"Original model restored\")\n",
    "except NameError as e:\n",
    "    print(f\"No model weights to restore: {e}\")\n",
    "\n",
    "# Colab-only: install deps for MEND* and KE*\n",
    "if IS_COLAB and not ALL_DEPS and any(x in ALG_NAME for x in [\"MEND\", \"KE\"]):\n",
    "    print(\"Installing additional dependencies required for MEND and KE\")\n",
    "    !pip install -r /content/rome/scripts/colab_reqs/additional.txt >> /content/install.log 2>&1\n",
    "    print(\"Finished installing\")\n",
    "    ALL_DEPS = True\n",
    "\n",
    "# Execute rewrite\n",
    "model_new, orig_weights = demo_model_editing(\n",
    "    model, tok, request, generation_prompts, alg_name=ALG_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae6d743",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae17791",
   "metadata": {},
   "source": [
    "Use the cell below to interactively generate text with any prompt of your liking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a488d43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generate_interactive(model_new, tok, max_out_len=100, use_logit_lens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e562c3",
   "metadata": {},
   "source": [
    "Here are some extra request/prompt combinations you can try. Simply run them before the editing cell!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da06a923",
   "metadata": {},
   "outputs": [],
   "source": [
    "request = [\n",
    "    {\n",
    "        \"prompt\": \"{} plays the sport of\",\n",
    "        \"subject\": \"LeBron James\",\n",
    "        \"target_new\": {\"str\": \"football\"},\n",
    "    }\n",
    "]\n",
    "\n",
    "generation_prompts = [\n",
    "    \"LeBron James plays for the\",\n",
    "    \"The greatest strength of LeBron James is his\",\n",
    "    \"LeBron James is widely regarded as one of the\",\n",
    "    \"LeBron James is known for his unstoppable\",\n",
    "    \"My favorite part of LeBron James' game is\",\n",
    "    \"LeBron James excels at\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea6565c",
   "metadata": {},
   "outputs": [],
   "source": [
    "request = [\n",
    "    {\n",
    "        \"prompt\": \"{} was developed by\",\n",
    "        \"subject\": \"Mario Kart\",\n",
    "        \"target_new\": {\n",
    "            \"str\": \"Apple\",\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "generation_prompts = [\n",
    "    \"Mario Kart was created by\",\n",
    "    \"I really want to get my hands on Mario Kart.\",\n",
    "    \"Mario Kart is\",\n",
    "    \"Which company created Mario Kart?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b8defa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
